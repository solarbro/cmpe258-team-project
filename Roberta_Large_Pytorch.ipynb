{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Roberta_Large_Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7d4fba2c61cb4bc9a1622ec54c27e1a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b7c54bb6c3e640fea269b2684cbe5786",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_af80078f87324baca4ff8cf875dd2e52",
              "IPY_MODEL_6bce9fbae99f43e1a49ced91edc5b012",
              "IPY_MODEL_d74a7dc947734a6bb311b92bac4db2e0"
            ]
          }
        },
        "b7c54bb6c3e640fea269b2684cbe5786": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "af80078f87324baca4ff8cf875dd2e52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_84c8c3a63c364b62a911614feff802e0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_444bba1feeee476f9a5778c18ad7d11c"
          }
        },
        "6bce9fbae99f43e1a49ced91edc5b012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4c8ad6a9dc644362ab3a62ee209ee5c2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5069051,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5069051,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0e7244dbb63a490895192cf209e01e51"
          }
        },
        "d74a7dc947734a6bb311b92bac4db2e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0b873ba18c9344ceb10fb22dbf117a77",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4.83M/4.83M [00:00&lt;00:00, 10.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb45faa9431942a38fe6c00f701659bd"
          }
        },
        "84c8c3a63c364b62a911614feff802e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "444bba1feeee476f9a5778c18ad7d11c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4c8ad6a9dc644362ab3a62ee209ee5c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0e7244dbb63a490895192cf209e01e51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b873ba18c9344ceb10fb22dbf117a77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb45faa9431942a38fe6c00f701659bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7979b595c7394111a7cad1dd7ff48117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5052bc7d00f4442fbd7721d90b44349a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1fb4f06c407246ee8186771de531c5a1",
              "IPY_MODEL_205508333061424ea57821541403a544",
              "IPY_MODEL_3ba06dbd1cac4801b507952413d33f36"
            ]
          }
        },
        "5052bc7d00f4442fbd7721d90b44349a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1fb4f06c407246ee8186771de531c5a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d2bd13b9e0fd4c06937e81026b964059",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_526adce35f6a4de5a7b296ed3108b93b"
          }
        },
        "205508333061424ea57821541403a544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_661eed9ac4094620b49fbd138cf063fb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9096718,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9096718,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c121752c32b47cc93fe789905baffeb"
          }
        },
        "3ba06dbd1cac4801b507952413d33f36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f72560c814cf4b389621b8b246191f68",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8.68M/8.68M [00:00&lt;00:00, 30.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5ca9f63b1c4a43089efde870b6df8f8e"
          }
        },
        "d2bd13b9e0fd4c06937e81026b964059": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "526adce35f6a4de5a7b296ed3108b93b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "661eed9ac4094620b49fbd138cf063fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c121752c32b47cc93fe789905baffeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f72560c814cf4b389621b8b246191f68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5ca9f63b1c4a43089efde870b6df8f8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c0bced55a9a44ba69227c5633a64ceef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_38637d6f6dde40119f5ecf6dd39c056d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_36584a4ca6064febb88a8c7bc2ae6333",
              "IPY_MODEL_b9f5b208f2654040a1a592aa15ce3237",
              "IPY_MODEL_0d4c1660b56544df9622e17c10e8e6bf"
            ]
          }
        },
        "38637d6f6dde40119f5ecf6dd39c056d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36584a4ca6064febb88a8c7bc2ae6333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4091aa65d72b4380b1ca877f84f60014",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_69b87a5bdf11456882664d11f4f723fd"
          }
        },
        "b9f5b208f2654040a1a592aa15ce3237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e57f9b3da5a14cb88532c6bae9b6fcc4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 512,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 512,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fcca6abb1c1e46bc8604640f1db8ba43"
          }
        },
        "0d4c1660b56544df9622e17c10e8e6bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8e03d1a505664c04a8a6c60f1f7f6680",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 512/512 [00:00&lt;00:00, 16.8kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f06c5b7763aa40b981756decf048acce"
          }
        },
        "4091aa65d72b4380b1ca877f84f60014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "69b87a5bdf11456882664d11f4f723fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e57f9b3da5a14cb88532c6bae9b6fcc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fcca6abb1c1e46bc8604640f1db8ba43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e03d1a505664c04a8a6c60f1f7f6680": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f06c5b7763aa40b981756decf048acce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5b4b59d4b1644edcba6640239cf03c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_48e87071dac141d385909a3bca7f00b2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aac14ddf2c8247899050b19156b44166",
              "IPY_MODEL_730d933fc2964800ac71479a8b43d066",
              "IPY_MODEL_b357bcf2e6f44f7db417941dfc8f6c12"
            ]
          }
        },
        "48e87071dac141d385909a3bca7f00b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aac14ddf2c8247899050b19156b44166": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9de776a1838a46f988fd0dff1b450699",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_625380bc19074497b8eae3e673d08c36"
          }
        },
        "730d933fc2964800ac71479a8b43d066": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_92c69005360e402eaa0fe82d6af54f7d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1115590446,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1115590446,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d2235de4c5814732bbf8373e1434f759"
          }
        },
        "b357bcf2e6f44f7db417941dfc8f6c12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_23423eaef7f44cb4884fdbe7fa96e866",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04G/1.04G [00:19&lt;00:00, 58.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_884f29e936db43489227ba6ba6fcff0a"
          }
        },
        "9de776a1838a46f988fd0dff1b450699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "625380bc19074497b8eae3e673d08c36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "92c69005360e402eaa0fe82d6af54f7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d2235de4c5814732bbf8373e1434f759": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "23423eaef7f44cb4884fdbe7fa96e866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "884f29e936db43489227ba6ba6fcff0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xZ2RLE6y_akV"
      },
      "source": [
        "#  XLM-Roberta model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-output": true,
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQTMPZcy_akX",
        "outputId": "b138c21b-af55-4249-ec0d-39013f767f16"
      },
      "source": [
        "# To use TPU\n",
        "\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  5116  100  5116    0     0  33657      0 --:--:-- --:--:-- --:--:-- 33657\n",
            "Updating... This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-dev20200515 ...\n",
            "Found existing installation: torch 1.10.0+cu111\n",
            "Collecting cloud-tpu-client\n",
            "  Downloading cloud_tpu_client-0.10-py3-none-any.whl (7.4 kB)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client) (4.1.3)\n",
            "Collecting google-api-python-client==1.8.0\n",
            "  Downloading google_api_python_client-1.8.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.26.3)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.35.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.0.4)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.17.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (3.0.1)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (57.4.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (21.3)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.17.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.53.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.23.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2018.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (0.2.8)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.0.6)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2021.10.8)\n",
            "Uninstalling torch-1.10.0+cu111:\n",
            "Installing collected packages: google-api-python-client, cloud-tpu-client\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 1.12.8\n",
            "    Uninstalling google-api-python-client-1.12.8:\n",
            "      Successfully uninstalled google-api-python-client-1.12.8\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "earthengine-api 0.1.290 requires google-api-python-client<2,>=1.12.1, but you have google-api-python-client 1.8.0 which is incompatible.\u001b[0m\n",
            "Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0\n",
            "Done updating TPU runtime\n",
            "  Successfully uninstalled torch-1.10.0+cu111\n",
            "Found existing installation: torchvision 0.11.1+cu111\n",
            "Uninstalling torchvision-0.11.1+cu111:\n",
            "  Successfully uninstalled torchvision-0.11.1+cu111\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly+20200515-cp37-cp37m-linux_x86_64.whl...\n",
            "- [1 files][ 91.0 MiB/ 91.0 MiB]                                                \n",
            "Operation completed over 1 objects/91.0 MiB.                                     \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200515-cp37-cp37m-linux_x86_64.whl...\n",
            "- [1 files][119.5 MiB/119.5 MiB]                                                \n",
            "Operation completed over 1 objects/119.5 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200515-cp37-cp37m-linux_x86_64.whl...\n",
            "/ [1 files][  2.3 MiB/  2.3 MiB]                                                \n",
            "Operation completed over 1 objects/2.3 MiB.                                      \n",
            "Processing ./torch-nightly+20200515-cp37-cp37m-linux_x86_64.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==nightly+20200515) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==nightly+20200515) (1.19.5)\n",
            "Installing collected packages: torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 1.0.61 requires torchvision, which is not installed.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.6.0a0+bf2bbd9\n",
            "Processing ./torch_xla-nightly+20200515-cp37-cp37m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "Successfully installed torch-xla-1.6+2b2085a\n",
            "Processing ./torchvision-nightly+20200515-cp37-cp37m-linux_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==nightly+20200515) (1.19.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchvision==nightly+20200515) (1.6.0a0+bf2bbd9)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==nightly+20200515) (7.1.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch->torchvision==nightly+20200515) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.7.0a0+a6073f0\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libopenblas-dev is already the newest version (0.2.20+ds-4).\n",
            "The following NEW packages will be installed:\n",
            "  libomp5\n",
            "0 upgraded, 1 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 234 kB of archives.\n",
            "After this operation, 774 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Fetched 234 kB in 1s (336 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 155222 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wuyIYQJ1_akZ"
      },
      "source": [
        "# Imports required to use TPUs with Pytorch.\n",
        "# https://pytorch.org/xla/release/1.5/index.html\n",
        "\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YnzhvwEAFV9",
        "outputId": "528d3bf4-cc9d-48ee-e40a-a92007788b45"
      },
      "source": [
        "!pip install transformers[sentencepiece] --quiet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.1 MB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 63.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 75.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 59 kB 7.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 73.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 70.0 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_kg_hide-output": true,
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGwSy7Dk_aka",
        "outputId": "79f4672c-67b3-413a-e2ea-15d041ea76f8"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import gc\n",
        "\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# set a seed value\n",
        "torch.manual_seed(555)\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "\n",
        "import transformers\n",
        "from transformers import BertTokenizer, BertForSequenceClassification \n",
        "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n",
        "from transformers import AdamW\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.6.0a0+bf2bbd9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOubzfCA_ak2"
      },
      "source": [
        "XLM means Cross-lingual Language Model. XLM-RoBERTa (XLM-R) is a pre-trained multilingual model that outperforms multiligual BERT. One reason for this is that XLM-R was trained using a lot more data. XLM-R was also trained on 100 languages.\n",
        "\n",
        "Several versions of xlm roberta are available in the Transformers library. Here are two:\n",
        "\n",
        "- xlm-roberta-base\n",
        "- xlm-roberta-large"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "7d4fba2c61cb4bc9a1622ec54c27e1a2",
            "b7c54bb6c3e640fea269b2684cbe5786",
            "af80078f87324baca4ff8cf875dd2e52",
            "6bce9fbae99f43e1a49ced91edc5b012",
            "d74a7dc947734a6bb311b92bac4db2e0",
            "84c8c3a63c364b62a911614feff802e0",
            "444bba1feeee476f9a5778c18ad7d11c",
            "4c8ad6a9dc644362ab3a62ee209ee5c2",
            "0e7244dbb63a490895192cf209e01e51",
            "0b873ba18c9344ceb10fb22dbf117a77",
            "fb45faa9431942a38fe6c00f701659bd",
            "7979b595c7394111a7cad1dd7ff48117",
            "5052bc7d00f4442fbd7721d90b44349a",
            "1fb4f06c407246ee8186771de531c5a1",
            "205508333061424ea57821541403a544",
            "3ba06dbd1cac4801b507952413d33f36",
            "d2bd13b9e0fd4c06937e81026b964059",
            "526adce35f6a4de5a7b296ed3108b93b",
            "661eed9ac4094620b49fbd138cf063fb",
            "4c121752c32b47cc93fe789905baffeb",
            "f72560c814cf4b389621b8b246191f68",
            "5ca9f63b1c4a43089efde870b6df8f8e",
            "c0bced55a9a44ba69227c5633a64ceef",
            "38637d6f6dde40119f5ecf6dd39c056d",
            "36584a4ca6064febb88a8c7bc2ae6333",
            "b9f5b208f2654040a1a592aa15ce3237",
            "0d4c1660b56544df9622e17c10e8e6bf",
            "4091aa65d72b4380b1ca877f84f60014",
            "69b87a5bdf11456882664d11f4f723fd",
            "e57f9b3da5a14cb88532c6bae9b6fcc4",
            "fcca6abb1c1e46bc8604640f1db8ba43",
            "8e03d1a505664c04a8a6c60f1f7f6680",
            "f06c5b7763aa40b981756decf048acce"
          ]
        },
        "id": "YSL-5fRR_ak3",
        "outputId": "d27d7a9f-913e-4fa9-ccfb-8130a27bfa01"
      },
      "source": [
        "# xml-roberta vocabulary\n",
        "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n",
        "\n",
        "MODEL_TYPE = 'xlm-roberta-base'\n",
        "\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained(MODEL_TYPE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d4fba2c61cb4bc9a1622ec54c27e1a2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7979b595c7394111a7cad1dd7ff48117",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0bced55a9a44ba69227c5633a64ceef",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/512 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeJzMNU4_ak3",
        "outputId": "1a64598b-2ff4-4f9b-ea13-098f04046261"
      },
      "source": [
        "# Check the vocab size\n",
        "\n",
        "tokenizer.vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "250002"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_iQp3BH_ak3",
        "outputId": "ed308cc0-35e6-4365-a67a-f87cd578d2ac"
      },
      "source": [
        "# What are the special tokens\n",
        "\n",
        "tokenizer.special_tokens_map"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bos_token': '<s>',\n",
              " 'cls_token': '<s>',\n",
              " 'eos_token': '</s>',\n",
              " 'mask_token': '<mask>',\n",
              " 'pad_token': '<pad>',\n",
              " 'sep_token': '</s>',\n",
              " 'unk_token': '<unk>'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZnuumyD_ak5"
      },
      "source": [
        "### For one input sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCV4q0LN_ak5",
        "outputId": "6d6b5b22-89c2-4979-8b39-08e3f69e648e"
      },
      "source": [
        "MAX_LEN = 10 # This value could be set as 256, 512 etc.\n",
        "\n",
        "sentence1 = 'Hello there.'\n",
        "\n",
        "encoded_dict = tokenizer.encode_plus(\n",
        "            sentence1,                \n",
        "            add_special_tokens = True,\n",
        "            max_length = MAX_LEN,     \n",
        "            pad_to_max_length = True,\n",
        "            return_attention_mask = True,  \n",
        "            return_tensors = 'pt' # return pytorch tensors\n",
        "       )\n",
        "\n",
        "\n",
        "encoded_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    0, 35378,  2685,     5,     2,     1,     1,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0yK6jxa_ak5",
        "outputId": "93881a4e-f482-45ca-f15e-f72581a2d9c8"
      },
      "source": [
        "# These have already been converted to torch tensors.\n",
        "input_ids = encoded_dict['input_ids'][0]\n",
        "att_mask = encoded_dict['attention_mask'][0]\n",
        "\n",
        "print(input_ids)\n",
        "print(att_mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([    0, 35378,  2685,     5,     2,     1,     1,     1,     1,     1])\n",
            "tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XgDkPh5_ak6"
      },
      "source": [
        "### For two input sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDbARtJZ_ak6",
        "outputId": "dbf6f3a4-60b4-4d72-f15b-c0c69d7721ac"
      },
      "source": [
        "MAX_LEN = 15\n",
        "\n",
        "sentence1 = 'Hello there.'\n",
        "sentence2 = 'How are you?'\n",
        "\n",
        "encoded_dict = tokenizer.encode_plus(\n",
        "            sentence1, sentence2,      \n",
        "            add_special_tokens = True,\n",
        "            max_length = MAX_LEN,     \n",
        "            pad_to_max_length = True,\n",
        "            return_attention_mask = True,   \n",
        "            return_tensors = 'pt' # return pytorch tensors\n",
        "       )\n",
        "\n",
        "\n",
        "encoded_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    0, 35378,  2685,     5,     2,     2, 11249,   621,   398,    32,\n",
              "             2,     1,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCvr1oQd_ak6",
        "outputId": "fbe98d87-1507-42ba-f008-a32f798eaec8"
      },
      "source": [
        "input_ids = encoded_dict['input_ids'][0]\n",
        "att_mask = encoded_dict['attention_mask'][0]\n",
        "\n",
        "# These are torch tensors.\n",
        "print(input_ids)\n",
        "print(att_mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([    0, 35378,  2685,     5,     2,     2, 11249,   621,   398,    32,\n",
            "            2,     1,     1,     1,     1])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5RnASlG_ak7"
      },
      "source": [
        "## Decoding a sequence of tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THatvs2v_ak7",
        "outputId": "70458208-abc0-4494-f4df-bfefadde3b16"
      },
      "source": [
        "# input_ids from above\n",
        "\n",
        "input_ids = encoded_dict['input_ids'][0]\n",
        "\n",
        "print(input_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([    0, 35378,  2685,     5,     2,     2, 11249,   621,   398,    32,\n",
            "            2,     1,     1,     1,     1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlniQs3e_ak8",
        "outputId": "2d17c4d3-78c3-44a6-e3b3-31d9b4039bb4"
      },
      "source": [
        "# https://huggingface.co/transformers/main_classes/tokenizer.html\n",
        "# skip_special_tokens – if set to True, will replace special tokens.\n",
        "\n",
        "a = tokenizer.decode(input_ids,\n",
        "                skip_special_tokens=False)\n",
        "\n",
        "b = tokenizer.decode(input_ids,\n",
        "                skip_special_tokens=True)\n",
        "\n",
        "\n",
        "\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> Hello there.</s></s> How are you?</s><pad><pad><pad><pad>\n",
            "Hello there. How are you?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GssYt95T_ak8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFErx9J4_ak9"
      },
      "source": [
        "| <a id='Manual_formatting_of_model_input_data'></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ApoTEuY_ak-",
        "outputId": "56fc22df-b541-4a34-9185-22fd23796f3a"
      },
      "source": [
        "MAX_LEN = 15 # This value could be set as 256, 512 etc.\n",
        "\n",
        "sentence1 = 'Hello there. How are you? Have a nice day. This is a test?'\n",
        "\n",
        "\n",
        "encoded_dict = tokenizer.encode_plus(\n",
        "            sentence1,                \n",
        "            max_length = MAX_LEN,\n",
        "            stride=0,\n",
        "            pad_to_max_length = True,\n",
        "            return_overflowing_tokens=True,\n",
        "       )\n",
        "\n",
        "\n",
        "encoded_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'overflowing_tokens': [83, 10, 3034, 32], 'num_truncated_tokens': 4, 'input_ids': [0, 35378, 2685, 5, 11249, 621, 398, 32, 31901, 10, 26267, 5155, 5, 3293, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3x2Iswk2_ak_",
        "outputId": "0beaefe1-e062-41c7-bfaf-269b6accbeb2"
      },
      "source": [
        "MAX_LEN = 15 # This value could be set as 256, 512 etc.\n",
        "\n",
        "sentence1 = 'Hello there. How are you? Have a nice day. This is a test?'\n",
        "\n",
        "\n",
        "encoded_dict = tokenizer.encode_plus(\n",
        "            sentence1,                \n",
        "            max_length = MAX_LEN,\n",
        "            stride=3,\n",
        "            pad_to_max_length = True,\n",
        "            return_overflowing_tokens=True,\n",
        "       )\n",
        "\n",
        "\n",
        "encoded_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'overflowing_tokens': [5155, 5, 3293, 83, 10, 3034, 32], 'num_truncated_tokens': 4, 'input_ids': [0, 35378, 2685, 5, 11249, 621, 398, 32, 31901, 10, 26267, 5155, 5, 3293, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1_24Z0l_ak_",
        "outputId": "9ed6e9a3-5f5b-43c1-a2e5-746637b5d4cd"
      },
      "source": [
        "# Here you can see the overlap.\n",
        "\n",
        "print(encoded_dict['input_ids'])\n",
        "print(encoded_dict['overflowing_tokens'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 35378, 2685, 5, 11249, 621, 398, 32, 31901, 10, 26267, 5155, 5, 3293, 2]\n",
            "[5155, 5, 3293, 83, 10, 3034, 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "gEO2MCqtAgys",
        "outputId": "6c6f6e66-ed27-4e75-c6ea-c80ad4cb188f"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-60d49b00-ae84-4c90-9cf4-bce8441e1347\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-60d49b00-ae84-4c90-9cf4-bce8441e1347\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "py78YvgRAgvD",
        "outputId": "d7f3efcd-18a9-409e-f8af-28613ae02c40"
      },
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CetFzyQNAgrY",
        "outputId": "e0a3e148-8693-4dd8-e25d-2d8782b42ad9"
      },
      "source": [
        "! kaggle competitions download contradictory-my-dear-watson"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading test.csv.zip to /content\n",
            "  0% 0.00/536k [00:00<?, ?B/s]\n",
            "100% 536k/536k [00:00<00:00, 78.6MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            "  0% 0.00/1.23M [00:00<?, ?B/s]\n",
            "100% 1.23M/1.23M [00:00<00:00, 84.6MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/66.0k [00:00<?, ?B/s]\n",
            "100% 66.0k/66.0k [00:00<00:00, 60.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeqJLGGdAgon",
        "outputId": "6133c167-5b9c-4450-cef9-7a7c19be9cce"
      },
      "source": [
        "!unzip train.csv.zip\n",
        "!unzip test.csv.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n",
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "nZzu1qlu_alB",
        "outputId": "297c65fc-01c9-43d6-d365-4c1c85ce1375"
      },
      "source": [
        "\n",
        "df_train = pd.read_csv('./train.csv')\n",
        "\n",
        "print(df_train.shape)\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12120, 6)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>lang_abv</th>\n",
              "      <th>language</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5130fd2cb5</td>\n",
              "      <td>and these comments were considered in formulat...</td>\n",
              "      <td>The rules developed in the interim were put to...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5b72532a0b</td>\n",
              "      <td>These are issues that we wrestle with in pract...</td>\n",
              "      <td>Practice groups are not permitted to work on t...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3931fbe82a</td>\n",
              "      <td>Des petites choses comme celles-là font une di...</td>\n",
              "      <td>J'essayais d'accomplir quelque chose.</td>\n",
              "      <td>fr</td>\n",
              "      <td>French</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5622f0c60b</td>\n",
              "      <td>you know they can't really defend themselves l...</td>\n",
              "      <td>They can't defend themselves because of their ...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>86aaa48b45</td>\n",
              "      <td>ในการเล่นบทบาทสมมุติก็เช่นกัน โอกาสที่จะได้แสด...</td>\n",
              "      <td>เด็กสามารถเห็นได้ว่าชาติพันธุ์แตกต่างกันอย่างไร</td>\n",
              "      <td>th</td>\n",
              "      <td>Thai</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  ... label\n",
              "0  5130fd2cb5  ...     0\n",
              "1  5b72532a0b  ...     2\n",
              "2  3931fbe82a  ...     0\n",
              "3  5622f0c60b  ...     0\n",
              "4  86aaa48b45  ...     1\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "73vzVGF1_alC",
        "outputId": "093a4282-9e63-459a-f4b3-eae3d3db99ad"
      },
      "source": [
        "\n",
        "df_test = pd.read_csv('./test.csv')\n",
        "\n",
        "print(df_test.shape)\n",
        "\n",
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5195, 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>lang_abv</th>\n",
              "      <th>language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c6d58c3f69</td>\n",
              "      <td>بکس، کیسی، راہیل، یسعیاہ، کیلی، کیلی، اور کولم...</td>\n",
              "      <td>کیسی کے لئے کوئی یادگار نہیں ہوگا, کولمین ہائی...</td>\n",
              "      <td>ur</td>\n",
              "      <td>Urdu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cefcc82292</td>\n",
              "      <td>هذا هو ما تم نصحنا به.</td>\n",
              "      <td>عندما يتم إخبارهم بما يجب عليهم فعله ، فشلت ال...</td>\n",
              "      <td>ar</td>\n",
              "      <td>Arabic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>e98005252c</td>\n",
              "      <td>et cela est en grande partie dû au fait que le...</td>\n",
              "      <td>Les mères se droguent.</td>\n",
              "      <td>fr</td>\n",
              "      <td>French</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>58518c10ba</td>\n",
              "      <td>与城市及其他公民及社区组织代表就IMA的艺术发展进行对话&amp;amp</td>\n",
              "      <td>IMA与其他组织合作，因为它们都依靠共享资金。</td>\n",
              "      <td>zh</td>\n",
              "      <td>Chinese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c32b0d16df</td>\n",
              "      <td>Она все еще была там.</td>\n",
              "      <td>Мы думали, что она ушла, однако, она осталась.</td>\n",
              "      <td>ru</td>\n",
              "      <td>Russian</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  ... language\n",
              "0  c6d58c3f69  ...     Urdu\n",
              "1  cefcc82292  ...   Arabic\n",
              "2  e98005252c  ...   French\n",
              "3  58518c10ba  ...  Chinese\n",
              "4  c32b0d16df  ...  Russian\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1WREpQe_alC"
      },
      "source": [
        "| <a id='Create_5_Folds'></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zqanDha_alD",
        "outputId": "c76aab3e-7ebd-4091-fc45-825e7b707027"
      },
      "source": [
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "\n",
        "# shuffle\n",
        "df = shuffle(df_train)\n",
        "\n",
        "# initialize kfold\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1024)\n",
        "\n",
        "# for stratification\n",
        "y = df['label']\n",
        "\n",
        "# Note:\n",
        "# Each fold is a tuple ([train_index_values], [val_index_values])\n",
        "# fold_0, fold_1, fold_2, fold_3, fold_5 = kf.split(df, y)\n",
        "\n",
        "# Put the folds into a list. This is a list of tuples.\n",
        "fold_list = list(kf.split(df, y))\n",
        "\n",
        "train_df_list = []\n",
        "val_df_list = []\n",
        "\n",
        "for i, fold in enumerate(fold_list):\n",
        "\n",
        "    # map the train and val index values to dataframe rows\n",
        "    df_train = df[df.index.isin(fold[0])]\n",
        "    df_val = df[df.index.isin(fold[1])]\n",
        "    \n",
        "    train_df_list.append(df_train)\n",
        "    val_df_list.append(df_val)\n",
        "    \n",
        "    \n",
        "\n",
        "print(len(train_df_list))\n",
        "print(len(val_df_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "KcHCAMU7_alD",
        "outputId": "9a32b818-21ee-46a4-8942-52a9271a65c3"
      },
      "source": [
        "# Display one train fold\n",
        "\n",
        "df_train = train_df_list[0]\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>lang_abv</th>\n",
              "      <th>language</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8670</th>\n",
              "      <td>89b8ed82f3</td>\n",
              "      <td>There's nothing like the trendy resort cloth...</td>\n",
              "      <td>There is no trendy resort clothing available h...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3520</th>\n",
              "      <td>458324e69c</td>\n",
              "      <td>So far, however, the number of mail pieces los...</td>\n",
              "      <td>The amount of mail lost is too smal  to leave ...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8547</th>\n",
              "      <td>6d101fabf4</td>\n",
              "      <td>Um-hum vizuri na ningekuwa nasema kuwa kuna ma...</td>\n",
              "      <td>Mimi nilikuwa naenda kupendekeza kupunguzwa kw...</td>\n",
              "      <td>sw</td>\n",
              "      <td>Swahili</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2647</th>\n",
              "      <td>e7cc1fd1d7</td>\n",
              "      <td>In addition, Saracens invaded the Provencal co...</td>\n",
              "      <td>The Magyar armies did not attack anyone.</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6225</th>\n",
              "      <td>8917f23f75</td>\n",
              "      <td>what was the problem</td>\n",
              "      <td>i know exactly what the problem is.</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              id  ... label\n",
              "8670  89b8ed82f3  ...     2\n",
              "3520  458324e69c  ...     0\n",
              "8547  6d101fabf4  ...     0\n",
              "2647  e7cc1fd1d7  ...     2\n",
              "6225  8917f23f75  ...     2\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "zQEn5dmY_alD",
        "outputId": "011d13d4-761e-4f3f-a22d-c1bb6a327b03"
      },
      "source": [
        "# Display one val fold\n",
        "\n",
        "df_val = val_df_list[0]\n",
        "\n",
        "df_val.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>lang_abv</th>\n",
              "      <th>language</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7026</th>\n",
              "      <td>d8aac27733</td>\n",
              "      <td>The chain wielder smiled at her.</td>\n",
              "      <td>The chain wielder frowned at her.</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3982</th>\n",
              "      <td>1bcdb7611d</td>\n",
              "      <td>Oh! I exclaimed, much relieved.</td>\n",
              "      <td>He was going to get the operation to remove hi...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4065</th>\n",
              "      <td>e42294e557</td>\n",
              "      <td>Là tổ chức chủ nhà địa phương cho Hội đồng quố...</td>\n",
              "      <td>Trung tâm nói không có du khách nào có thể đến.</td>\n",
              "      <td>vi</td>\n",
              "      <td>Vietnamese</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4272</th>\n",
              "      <td>88675218ef</td>\n",
              "      <td>یہودی مقصود کے مقابلے میں عام قسمت کا احساس کہ...</td>\n",
              "      <td>یہودی لوگوں کو اپنے عقائد کو سکھانے کے لئے چاہ...</td>\n",
              "      <td>ur</td>\n",
              "      <td>Urdu</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5477</th>\n",
              "      <td>5f47d9eebe</td>\n",
              "      <td>Mfululizo wa mashindano ya uvuvi hufanya msimu...</td>\n",
              "      <td>Watu hupenda kunywa pombe nyingi kwenye baa wa...</td>\n",
              "      <td>sw</td>\n",
              "      <td>Swahili</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              id  ... label\n",
              "7026  d8aac27733  ...     2\n",
              "3982  1bcdb7611d  ...     1\n",
              "4065  e42294e557  ...     2\n",
              "4272  88675218ef  ...     1\n",
              "5477  5f47d9eebe  ...     1\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBXs0_FO_alZ",
        "outputId": "3fc3c897-e486-4138-d7e2-811b7c31d688"
      },
      "source": [
        "# Train Roberta model\n",
        "MODEL_TYPE = 'xlm-roberta-base'\n",
        "\n",
        "\n",
        "L_RATE = 1e-5\n",
        "MAX_LEN = 256\n",
        "\n",
        "NUM_EPOCHS = 3\n",
        "BATCH_SIZE = 32\n",
        "NUM_CORES = os.cpu_count()\n",
        "\n",
        "NUM_CORES"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "3Vi0ybw6_ala",
        "outputId": "887ed2df-c74d-424e-efc3-0b0d6171ab98"
      },
      "source": [
        "df_train = train_df_list[0]\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>lang_abv</th>\n",
              "      <th>language</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8670</th>\n",
              "      <td>89b8ed82f3</td>\n",
              "      <td>There's nothing like the trendy resort cloth...</td>\n",
              "      <td>There is no trendy resort clothing available h...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3520</th>\n",
              "      <td>458324e69c</td>\n",
              "      <td>So far, however, the number of mail pieces los...</td>\n",
              "      <td>The amount of mail lost is too smal  to leave ...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8547</th>\n",
              "      <td>6d101fabf4</td>\n",
              "      <td>Um-hum vizuri na ningekuwa nasema kuwa kuna ma...</td>\n",
              "      <td>Mimi nilikuwa naenda kupendekeza kupunguzwa kw...</td>\n",
              "      <td>sw</td>\n",
              "      <td>Swahili</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2647</th>\n",
              "      <td>e7cc1fd1d7</td>\n",
              "      <td>In addition, Saracens invaded the Provencal co...</td>\n",
              "      <td>The Magyar armies did not attack anyone.</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6225</th>\n",
              "      <td>8917f23f75</td>\n",
              "      <td>what was the problem</td>\n",
              "      <td>i know exactly what the problem is.</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              id  ... label\n",
              "8670  89b8ed82f3  ...     2\n",
              "3520  458324e69c  ...     0\n",
              "8547  6d101fabf4  ...     0\n",
              "2647  e7cc1fd1d7  ...     2\n",
              "6225  8917f23f75  ...     2\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "69yPoT3l_ala",
        "outputId": "d46ec52e-80ba-4186-b258-c9cfd507ef18"
      },
      "source": [
        "df_val = val_df_list[0]\n",
        "\n",
        "df_val.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>premise</th>\n",
              "      <th>hypothesis</th>\n",
              "      <th>lang_abv</th>\n",
              "      <th>language</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7026</th>\n",
              "      <td>d8aac27733</td>\n",
              "      <td>The chain wielder smiled at her.</td>\n",
              "      <td>The chain wielder frowned at her.</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3982</th>\n",
              "      <td>1bcdb7611d</td>\n",
              "      <td>Oh! I exclaimed, much relieved.</td>\n",
              "      <td>He was going to get the operation to remove hi...</td>\n",
              "      <td>en</td>\n",
              "      <td>English</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4065</th>\n",
              "      <td>e42294e557</td>\n",
              "      <td>Là tổ chức chủ nhà địa phương cho Hội đồng quố...</td>\n",
              "      <td>Trung tâm nói không có du khách nào có thể đến.</td>\n",
              "      <td>vi</td>\n",
              "      <td>Vietnamese</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4272</th>\n",
              "      <td>88675218ef</td>\n",
              "      <td>یہودی مقصود کے مقابلے میں عام قسمت کا احساس کہ...</td>\n",
              "      <td>یہودی لوگوں کو اپنے عقائد کو سکھانے کے لئے چاہ...</td>\n",
              "      <td>ur</td>\n",
              "      <td>Urdu</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5477</th>\n",
              "      <td>5f47d9eebe</td>\n",
              "      <td>Mfululizo wa mashindano ya uvuvi hufanya msimu...</td>\n",
              "      <td>Watu hupenda kunywa pombe nyingi kwenye baa wa...</td>\n",
              "      <td>sw</td>\n",
              "      <td>Swahili</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              id  ... label\n",
              "7026  d8aac27733  ...     2\n",
              "3982  1bcdb7611d  ...     1\n",
              "4065  e42294e557  ...     2\n",
              "4272  88675218ef  ...     1\n",
              "5477  5f47d9eebe  ...     1\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78rWR1-1_alb",
        "outputId": "f231fd32-c2e3-452f-c4fc-6cd93d7dc451"
      },
      "source": [
        "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n",
        "\n",
        "# xlm-roberta-large\n",
        "print('Loading XLMRoberta tokenizer...')\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained(MODEL_TYPE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading XLMRoberta tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mkEiPE6N_alc"
      },
      "source": [
        "df_train = df_train.reset_index(drop=True)\n",
        "df_val = df_val.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HdX8TFof_alc"
      },
      "source": [
        "class CompDataset(Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "        self.df_data = df\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # get the sentence from the dataframe\n",
        "        sentence1 = self.df_data.loc[index, 'premise']\n",
        "        sentence2 = self.df_data.loc[index, 'hypothesis']\n",
        "\n",
        "        # Process the sentence\n",
        "        # ---------------------\n",
        "\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                    sentence1, sentence2,           # Sentences to encode.\n",
        "                    add_special_tokens = True,      # Add the special tokens.\n",
        "                    max_length = MAX_LEN,           # Pad & truncate all sentences.\n",
        "                    pad_to_max_length = True,\n",
        "                    truncation = True,\n",
        "                    return_attention_mask = True,   # Construct attn. masks.\n",
        "                    return_tensors = 'pt',          # Return pytorch tensors.\n",
        "               )\n",
        "        \n",
        "        # These are torch tensors.\n",
        "        padded_token_list = encoded_dict['input_ids'][0]\n",
        "        att_mask = encoded_dict['attention_mask'][0]\n",
        "        \n",
        "        # Convert the target to a torch tensor\n",
        "        target = torch.tensor(self.df_data.loc[index, 'label'])\n",
        "\n",
        "        sample = (padded_token_list, att_mask, target)\n",
        "\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df_data)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "class TestDataset(Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "        self.df_data = df\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # get the sentence from the dataframe\n",
        "        sentence1 = self.df_data.loc[index, 'premise']\n",
        "        sentence2 = self.df_data.loc[index, 'hypothesis']\n",
        "\n",
        "        # Process the sentence\n",
        "        # ---------------------\n",
        "\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                    sentence1, sentence2,           # Sentence to encode.\n",
        "                    add_special_tokens = True,      # Add the special tokens.\n",
        "                    max_length = MAX_LEN,           # Pad & truncate all sentences.\n",
        "                    pad_to_max_length = True,\n",
        "                    truncation = True,\n",
        "                    return_attention_mask = True,   # Construct attn. masks.\n",
        "                    return_tensors = 'pt',          # Return pytorch tensors.\n",
        "               )\n",
        "        \n",
        "        # These are torch tensors.\n",
        "        padded_token_list = encoded_dict['input_ids'][0]\n",
        "        att_mask = encoded_dict['attention_mask'][0]\n",
        "        \n",
        "               \n",
        "\n",
        "        sample = (padded_token_list, att_mask)\n",
        "\n",
        "\n",
        "        return sample\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tU6nD32Q_alg",
        "outputId": "b88295a2-f657-46a4-924f-0c65ba84dac4"
      },
      "source": [
        "train_data = CompDataset(df_train)\n",
        "val_data = CompDataset(df_val)\n",
        "test_data = TestDataset(df_test)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_data,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        shuffle=True,\n",
        "                                       num_workers=NUM_CORES)\n",
        "\n",
        "val_dataloader = torch.utils.data.DataLoader(val_data,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        shuffle=True,\n",
        "                                       num_workers=NUM_CORES)\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(test_data,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        shuffle=False,\n",
        "                                       num_workers=NUM_CORES)\n",
        "\n",
        "\n",
        "\n",
        "print(len(train_dataloader))\n",
        "print(len(val_dataloader))\n",
        "print(len(test_dataloader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "303\n",
            "76\n",
            "163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00oitxzY_alh",
        "outputId": "52fdd0fd-3a58-48c3-e137-a802bd7abe06"
      },
      "source": [
        "# Get one train batch\n",
        "\n",
        "padded_token_list, att_mask, target = next(iter(train_dataloader))\n",
        "\n",
        "print(padded_token_list.shape)\n",
        "print(att_mask.shape)\n",
        "print(target.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 256])\n",
            "torch.Size([32, 256])\n",
            "torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OO7FELco_alh",
        "outputId": "7605cf14-1fef-4bd2-c07f-d05856ce322f"
      },
      "source": [
        "# Get one val batch\n",
        "\n",
        "padded_token_list, att_mask, target = next(iter(val_dataloader))\n",
        "\n",
        "print(padded_token_list.shape)\n",
        "print(att_mask.shape)\n",
        "print(target.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 256])\n",
            "torch.Size([32, 256])\n",
            "torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5ouIbbL_ali",
        "outputId": "3ce2327b-c7fb-42ae-f79a-ccfaed904f18"
      },
      "source": [
        "# Get one test batch\n",
        "\n",
        "padded_token_list, att_mask = next(iter(test_dataloader))\n",
        "\n",
        "print(padded_token_list.shape)\n",
        "print(att_mask.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 256])\n",
            "torch.Size([32, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-output": true,
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5b4b59d4b1644edcba6640239cf03c17",
            "48e87071dac141d385909a3bca7f00b2",
            "aac14ddf2c8247899050b19156b44166",
            "730d933fc2964800ac71479a8b43d066",
            "b357bcf2e6f44f7db417941dfc8f6c12",
            "9de776a1838a46f988fd0dff1b450699",
            "625380bc19074497b8eae3e673d08c36",
            "92c69005360e402eaa0fe82d6af54f7d",
            "d2235de4c5814732bbf8373e1434f759",
            "23423eaef7f44cb4884fdbe7fa96e866",
            "884f29e936db43489227ba6ba6fcff0a"
          ]
        },
        "id": "0aRXphsX_alj",
        "outputId": "926bf83e-ba47-442a-ba53-d28abb939252"
      },
      "source": [
        "from transformers import XLMRobertaForSequenceClassification\n",
        "\n",
        "model = XLMRobertaForSequenceClassification.from_pretrained(\n",
        "    MODEL_TYPE, \n",
        "    num_labels = 3, # The number of output labels. 2 for binary classification.\n",
        ")\n",
        "\n",
        "# Send the model to the device.\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b4b59d4b1644edcba6640239cf03c17",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.04G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLMRobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp2YkBwB_alk",
        "outputId": "f94dbb27-bb44-405e-e726-3b1ca81b2dcf"
      },
      "source": [
        "# Create a batch of train samples\n",
        "\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_data,\n",
        "                                        batch_size=8,\n",
        "                                        shuffle=True,\n",
        "                                       num_workers=NUM_CORES)\n",
        "\n",
        "b_input_ids, b_input_mask, b_labels = next(iter(train_dataloader))\n",
        "\n",
        "print(b_input_ids.shape)\n",
        "print(b_input_mask.shape)\n",
        "print(b_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 256])\n",
            "torch.Size([8, 256])\n",
            "torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPWT1wUk_alk",
        "outputId": "401c7031-f644-4015-9a49-dee6d1af9235"
      },
      "source": [
        "# Pass a batch of train samples to the model.\n",
        "\n",
        "batch = next(iter(train_dataloader))\n",
        "\n",
        "# Send the data to the device\n",
        "b_input_ids = batch[0].to(device)\n",
        "b_input_mask = batch[1].to(device)\n",
        "b_labels = batch[2].to(device)\n",
        "\n",
        "# Run the model\n",
        "outputs = model(b_input_ids, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels)\n",
        "\n",
        "# The ouput is a tuple (loss, preds).\n",
        "outputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/util.py\", line 300, in _run_finalizers\n",
            "    finalizer()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/util.py\", line 224, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
            "    rmtree(tempdir)\n",
            "  File \"/usr/lib/python3.7/shutil.py\", line 498, in rmtree\n",
            "    onerror(os.rmdir, path, sys.exc_info())\n",
            "  File \"/usr/lib/python3.7/shutil.py\", line 496, in rmtree\n",
            "    os.rmdir(path)\n",
            "OSError: [Errno 39] Directory not empty: '/tmp/pymp-ec9_6_l0'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequenceClassifierOutput([('loss', tensor(1.1962, device='xla:1')),\n",
              "                          ('logits', tensor([[ 0.3614, -0.0760,  0.3286],\n",
              "                                   [ 0.3700, -0.0999,  0.3229],\n",
              "                                   [ 0.3561, -0.0863,  0.3226],\n",
              "                                   [ 0.3579, -0.1016,  0.3209],\n",
              "                                   [ 0.3281, -0.0359,  0.2813],\n",
              "                                   [ 0.3232, -0.0537,  0.3000],\n",
              "                                   [ 0.3711, -0.0893,  0.3195],\n",
              "                                   [ 0.3499, -0.0808,  0.3103]], device='xla:1'))])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbHHuGr9_all"
      },
      "source": [
        "## Inspect the model's output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aU_ucRsS_all",
        "outputId": "c12209cf-a7dd-403c-863d-4f881510188b"
      },
      "source": [
        "outputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequenceClassifierOutput([('loss', tensor(1.1962, device='xla:1')),\n",
              "                          ('logits', tensor([[ 0.3614, -0.0760,  0.3286],\n",
              "                                   [ 0.3700, -0.0999,  0.3229],\n",
              "                                   [ 0.3561, -0.0863,  0.3226],\n",
              "                                   [ 0.3579, -0.1016,  0.3209],\n",
              "                                   [ 0.3281, -0.0359,  0.2813],\n",
              "                                   [ 0.3232, -0.0537,  0.3000],\n",
              "                                   [ 0.3711, -0.0893,  0.3195],\n",
              "                                   [ 0.3499, -0.0808,  0.3103]], device='xla:1'))])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSM0CGVp_all",
        "outputId": "d08a1270-fac7-4068-8df7-c7f8080ce2a8"
      },
      "source": [
        "# The output is a tuple: (loss, preds)\n",
        "\n",
        "len(outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGOXtsXP_alm",
        "outputId": "3fe582ba-f7f9-4f7a-eec1-3798e9442bfb"
      },
      "source": [
        "# This is the loss.\n",
        "\n",
        "outputs[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.1962, device='xla:1')"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Z88Qy1J_aln",
        "outputId": "5e9d32e9-145f-45c6-aa78-a3bd864dc066"
      },
      "source": [
        "# These are the predictions.\n",
        "\n",
        "outputs[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3614, -0.0760,  0.3286],\n",
              "        [ 0.3700, -0.0999,  0.3229],\n",
              "        [ 0.3561, -0.0863,  0.3226],\n",
              "        [ 0.3579, -0.1016,  0.3209],\n",
              "        [ 0.3281, -0.0359,  0.2813],\n",
              "        [ 0.3232, -0.0537,  0.3000],\n",
              "        [ 0.3711, -0.0893,  0.3195],\n",
              "        [ 0.3499, -0.0808,  0.3103]], device='xla:1')"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2u75rehh_aln",
        "outputId": "828cdba7-d308-4b96-b85b-00a0c90fdc04"
      },
      "source": [
        "preds = outputs[1].detach().cpu().numpy()\n",
        "\n",
        "y_true = b_labels.detach().cpu().numpy()\n",
        "y_pred = np.argmax(preds, axis=1)\n",
        "\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0ZeRCbr_alo",
        "outputId": "792464d0-776f-4fbe-a251-cadb261f4ca6"
      },
      "source": [
        "# This is the accuracy without fine tuning.\n",
        "\n",
        "val_acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "val_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.125"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiJKLmOx_alo",
        "outputId": "9e36f9f7-7f97-4690-8ca8-d2b3b94989c8"
      },
      "source": [
        "# The loss and preds are Torch tensors\n",
        "\n",
        "print(type(outputs[0]))\n",
        "print(type(outputs[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek3twTuY_alp"
      },
      "source": [
        "## Define the Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vLJ2_7Yz_alq"
      },
      "source": [
        "# Define the optimizer\n",
        "optimizer = AdamW(model.parameters(),\n",
        "              lr = L_RATE, \n",
        "              eps = 1e-8 \n",
        "            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBbinuGn_alq"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUOoGEFW_alq",
        "outputId": "c707bda4-5045-45d0-b874-d50155353637"
      },
      "source": [
        "# Create the dataloaders.\n",
        "\n",
        "train_data = CompDataset(df_train)\n",
        "val_data = CompDataset(df_val)\n",
        "test_data = TestDataset(df_test)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_data,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        shuffle=True,\n",
        "                                       num_workers=NUM_CORES)\n",
        "\n",
        "val_dataloader = torch.utils.data.DataLoader(val_data,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        shuffle=True,\n",
        "                                       num_workers=NUM_CORES)\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(test_data,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        shuffle=False,\n",
        "                                       num_workers=NUM_CORES)\n",
        "\n",
        "\n",
        "\n",
        "print(len(train_dataloader))\n",
        "print(len(val_dataloader))\n",
        "print(len(test_dataloader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "303\n",
            "76\n",
            "163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ei_q4GPO_alr",
        "outputId": "10eb2e63-4d98-4843-8e7b-a93ad917587c"
      },
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "# Set the seed.\n",
        "seed_val = 101\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "\n",
        "# For each epoch...\n",
        "for epoch in range(0, NUM_EPOCHS):\n",
        "    \n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch + 1, NUM_EPOCHS))\n",
        "    \n",
        "\n",
        "    stacked_val_labels = []\n",
        "    targets_list = []\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    print('Training...')\n",
        "    \n",
        "    # put the model into train mode\n",
        "    model.train()\n",
        "    \n",
        "    # This turns gradient calculations on and off.\n",
        "    torch.set_grad_enabled(True)\n",
        "\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "        \n",
        "        train_status = 'Batch ' + str(i) + ' of ' + str(len(train_dataloader))\n",
        "        \n",
        "        print(train_status, end='\\r')\n",
        "\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "\n",
        "        outputs = model(b_input_ids, \n",
        "                    attention_mask=b_input_mask,\n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # Get the loss from the outputs tuple: (loss, logits)\n",
        "        loss = outputs[0]\n",
        "        \n",
        "        # Convert the loss from a torch tensor to a number.\n",
        "        # Calculate the total loss.\n",
        "        total_train_loss = total_train_loss + loss.item()\n",
        "        \n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "        \n",
        "        \n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        \n",
        "        \n",
        "        \n",
        "        # Use the optimizer to update the weights.\n",
        "        \n",
        "        # Optimizer for GPU\n",
        "        # optimizer.step() \n",
        "        \n",
        "        # Optimizer for TPU\n",
        "        # https://pytorch.org/xla/\n",
        "        xm.optimizer_step(optimizer, barrier=True)\n",
        "\n",
        "    \n",
        "    print('Train loss:' ,total_train_loss)\n",
        "\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    \n",
        "    print('\\nValidation...')\n",
        "\n",
        "    # Put the model in evaluation mode.\n",
        "    model.eval()\n",
        "\n",
        "    # Turn off the gradient calculations.\n",
        "    # This tells the model not to compute or store gradients.\n",
        "    # This step saves memory and speeds up validation.\n",
        "    torch.set_grad_enabled(False)\n",
        "    \n",
        "    \n",
        "    # Reset the total loss for this epoch.\n",
        "    total_val_loss = 0\n",
        "    \n",
        "\n",
        "    for j, batch in enumerate(val_dataloader):\n",
        "        \n",
        "        val_status = 'Batch ' + str(j) + ' of ' + str(len(val_dataloader))\n",
        "        \n",
        "        print(val_status, end='\\r')\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)      \n",
        "\n",
        "\n",
        "        outputs = model(b_input_ids, \n",
        "                attention_mask=b_input_mask, \n",
        "                labels=b_labels)\n",
        "        \n",
        "        # Get the loss from the outputs tuple: (loss, logits)\n",
        "        loss = outputs[0]\n",
        "        \n",
        "        # Convert the loss from a torch tensor to a number.\n",
        "        # Calculate the total loss.\n",
        "        total_val_loss = total_val_loss + loss.item()\n",
        "        \n",
        "\n",
        "        # Get the preds\n",
        "        preds = outputs[1]\n",
        "\n",
        "\n",
        "        # Move preds to the CPU\n",
        "        val_preds = preds.detach().cpu().numpy()\n",
        "        \n",
        "        # Move the labels to the cpu\n",
        "        targets_np = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Append the labels to a numpy list\n",
        "        targets_list.extend(targets_np)\n",
        "\n",
        "        if j == 0:  # first batch\n",
        "            stacked_val_preds = val_preds\n",
        "\n",
        "        else:\n",
        "            stacked_val_preds = np.vstack((stacked_val_preds, val_preds))\n",
        "\n",
        "    \n",
        "    # Calculate the validation accuracy\n",
        "    y_true = targets_list\n",
        "    y_pred = np.argmax(stacked_val_preds, axis=1)\n",
        "    \n",
        "    val_acc = accuracy_score(y_true, y_pred)\n",
        "    \n",
        "    \n",
        "    print('Val loss:' ,total_val_loss)\n",
        "    print('Val acc: ', val_acc)\n",
        "\n",
        "\n",
        "    # Save the Model\n",
        "    torch.save(model.state_dict(), 'model.pt')\n",
        "    \n",
        "    # Use the garbage collector to save memory.\n",
        "    gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "Train loss: 327.86276692152023\n",
            "\n",
            "Validation...\n",
            "Val loss: 75.82385063171387\n",
            "Val acc:  0.5371287128712872\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "Train loss: 268.60993725061417\n",
            "\n",
            "Validation...\n",
            "Val loss: 56.32665252685547\n",
            "Val acc:  0.6951320132013201\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "Train loss: 218.642987459898\n",
            "\n",
            "Validation...\n",
            "Val loss: 53.42127624154091\n",
            "Val acc:  0.7157590759075908\n",
            "CPU times: user 7min 27s, sys: 56.8 s, total: 8min 24s\n",
            "Wall time: 16min 34s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pBXPtxa_alt",
        "outputId": "1241be66-ac72-4881-aaa0-160d6a8b58ac"
      },
      "source": [
        "for j, batch in enumerate(test_dataloader):\n",
        "        \n",
        "        inference_status = 'Batch ' + str(j+1) + ' of ' + str(len(test_dataloader))\n",
        "        \n",
        "        print(inference_status, end='\\r')\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "\n",
        "\n",
        "        outputs = model(b_input_ids, \n",
        "                attention_mask=b_input_mask)\n",
        "        \n",
        "        \n",
        "        # Get the preds\n",
        "        preds = outputs[0]\n",
        "\n",
        "\n",
        "        # Move preds to the CPU\n",
        "        preds = preds.detach().cpu().numpy()\n",
        "        \n",
        "        # Move the labels to the cpu\n",
        "        targets_np = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Append the labels to a numpy list\n",
        "        targets_list.extend(targets_np)\n",
        "        \n",
        "        # Stack the predictions.\n",
        "\n",
        "        if j == 0:  # first batch\n",
        "            stacked_preds = preds\n",
        "\n",
        "        else:\n",
        "            stacked_preds = np.vstack((stacked_preds, preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rixA4ms5_alw",
        "outputId": "34104266-7174-4854-9d5a-6629d3a92428"
      },
      "source": [
        "stacked_preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.591747  , -0.46209022,  0.47971505],\n",
              "       [-1.4384645 ,  0.59447134,  0.41534314],\n",
              "       [ 1.6042563 , -0.89423877, -1.1976119 ],\n",
              "       ...,\n",
              "       [ 0.8453864 , -0.5440602 , -0.9371083 ],\n",
              "       [ 2.2397861 , -1.3524817 , -1.075075  ],\n",
              "       [-0.91773313, -1.6126078 ,  2.4981465 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PV7VYNb_alw"
      },
      "source": [
        "## Process the Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyYkQJ11_alw",
        "outputId": "daa2b26c-66d4-4105-ad2f-5e8ebe4d93c6"
      },
      "source": [
        "# Take the argmax. This returns the column index of the max value in each row.\n",
        "\n",
        "preds = np.argmax(stacked_preds, axis=1)\n",
        "\n",
        "preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 0, ..., 0, 0, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnHuazXB_alx"
      },
      "source": [
        "## Create a submission csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "elgYyK0G_alx",
        "outputId": "d38558ed-96a7-4a04-c691-ae6c4e03e532"
      },
      "source": [
        "\n",
        "df_sample = pd.read_csv('./sample_submission.csv')\n",
        "\n",
        "print(df_sample.shape)\n",
        "\n",
        "df_sample.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5195, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c6d58c3f69</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cefcc82292</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>e98005252c</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>58518c10ba</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c32b0d16df</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  prediction\n",
              "0  c6d58c3f69           1\n",
              "1  cefcc82292           1\n",
              "2  e98005252c           1\n",
              "3  58518c10ba           1\n",
              "4  c32b0d16df           1"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "mjmjZQjH_alx",
        "outputId": "f77d222f-4619-4a54-892b-0c8b492726aa"
      },
      "source": [
        "# Assign the preds to the prediction column\n",
        "\n",
        "df_sample['prediction'] = preds\n",
        "\n",
        "df_sample.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c6d58c3f69</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cefcc82292</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>e98005252c</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>58518c10ba</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c32b0d16df</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  prediction\n",
              "0  c6d58c3f69           2\n",
              "1  cefcc82292           1\n",
              "2  e98005252c           0\n",
              "3  58518c10ba           1\n",
              "4  c32b0d16df           2"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "m5PgRtbR_aly"
      },
      "source": [
        "\n",
        "df_sample.to_csv('xlmroberta_submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymrYBewL_alz",
        "outputId": "f28e8960-766e-4313-c15b-912c43e299db"
      },
      "source": [
        "# Check the distribution of the predicted classes.\n",
        "\n",
        "df_sample['prediction'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1766\n",
              "2    1734\n",
              "0    1695\n",
              "Name: prediction, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    }
  ]
}